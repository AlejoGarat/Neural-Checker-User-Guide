{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Checker User Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to provide a step-by-step guide to using the Neural Checker tool. It is developed by the team of Artificial Intelligence and Big Data of the Universidad ORT. Its main goal is to provide implementations for the structures needed for working in the Model Extraction Framework and enable the explainability and checking of complex systems in a black box context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythautomata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pythautomata in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (0.39.1)\n",
      "Requirement already satisfied: numpy in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pythautomata) (1.26.4)\n",
      "Requirement already satisfied: graphviz in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pythautomata) (0.20.3)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.1 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pythautomata) (1.4.1.post1)\n",
      "Requirement already satisfied: pydot<2.0.0,>=1.4.2 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pythautomata) (1.4.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.7.3 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pythautomata) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pydot<2.0.0,>=1.4.2->pythautomata) (3.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.2.1->pythautomata) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.2.1->pythautomata) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pythautomata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moore machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.base_types.alphabet import Alphabet\n",
    "from pythautomata.base_types.moore_state import MooreState\n",
    "from pythautomata.base_types.symbol import SymbolStr\n",
    "from pythautomata.automata.moore_machine_automaton import MooreMachineAutomaton\n",
    "from pythautomata.model_comparators.moore_machine_comparison_strategy import MooreMachineComparisonStrategy as ComparisonStrategy\n",
    "from pythautomata.model_exporters.dot_exporters.moore_dot_exporting_strategy import MooreDotExportingStrategy as DotExportingMMStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create an input alphabet with symbols a, b and c\n",
    "input_alphabet = Alphabet(frozenset((SymbolStr('a'), SymbolStr('b'), SymbolStr('c'))))\n",
    "# Then the output alphabet with symbols 0 and 1\n",
    "output_alphabet = Alphabet(frozenset((SymbolStr('0'), SymbolStr('1'))))\n",
    "\n",
    "a = input_alphabet['a']\n",
    "b = input_alphabet['b']\n",
    "c = input_alphabet['c']\n",
    "\n",
    "# Defining moore states\n",
    "stateA = MooreState(name=\"State A\", value=output_alphabet['0'])\n",
    "stateB = MooreState(\"State B\", output_alphabet['1'])\n",
    "stateC = MooreState(\"State C\", output_alphabet['1'])\n",
    "\n",
    "# Adding transitions for the previous states\n",
    "stateA.add_transition(a, stateA)\n",
    "stateA.add_transition(b, stateB)\n",
    "stateB.add_transition(a, stateC)\n",
    "stateB.add_transition(c, stateB)\n",
    "\n",
    "# Finaly we create the moore machine with the alphabets and states previously created \n",
    "moore_machine = MooreMachineAutomaton(input_alphabet, output_alphabet, initial_state=stateA, \n",
    "                                      states=set([stateA, stateB, stateC]), comparator=ComparisonStrategy, \n",
    "                                      name=\"moore machine with 3 states\")\n",
    "\n",
    "# Moore machine is exported in the directory ./output_models/moore_machines/ with .dot extension\n",
    "moore_machine.export('./output_models/moore_machines/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mealy machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.base_types.alphabet import Alphabet\n",
    "from pythautomata.base_types.mealy_state import MealyState\n",
    "from pythautomata.base_types.symbol import SymbolStr\n",
    "from pythautomata.automata.mealy_machine import MealyMachine\n",
    "from pythautomata.model_comparators.mealy_machine_comparison_strategy import MealyMachineComparisonStrategy as MealyComparisonStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create an input alphabet with symbols a, b and c\n",
    "input_alphabet = Alphabet(frozenset((SymbolStr('a'), SymbolStr('b'), SymbolStr('c'))))\n",
    "# Then the output alphabet with symbols 0 and 1\n",
    "output_alphabet = Alphabet(frozenset((SymbolStr('0'), SymbolStr('1'))))\n",
    "\n",
    "a = input_alphabet['a']\n",
    "b = input_alphabet['b']\n",
    "c = input_alphabet['c']\n",
    "\n",
    "zero = output_alphabet['0']\n",
    "one = output_alphabet['1']\n",
    "\n",
    "# Defining mealy states\n",
    "stateA = MealyState(name=\"State A\")\n",
    "stateB = MealyState(name=\"State B\")\n",
    "stateC = MealyState(name=\"State C\")\n",
    "\n",
    "# Adding transitions for the previous states\n",
    "stateA.add_transition(a, stateA, zero)\n",
    "stateA.add_transition(b, stateB, one)\n",
    "stateB.add_transition(a, stateC, zero)\n",
    "stateB.add_transition(c, stateB, one)\n",
    "\n",
    "# Finaly we create the mealy machine with the alphabets and states previously created \n",
    "mealy_machine = MealyMachine(input_alphabet, output_alphabet, initial_state=stateA, states=set([stateA, stateB, stateC]), \n",
    "                             comparator=MealyComparisonStrategy, \n",
    "                             name=\"mealy machine with 3 states\")\n",
    "\n",
    "# Mealy machine is exported in the directory ./output_models/mealy_machines/ with .dot extension\n",
    "mealy_machine.export('./output_models/mealy_machines/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moore machine generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.utilities.nicaud_mm_generator import generate_moore_machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random Moore Machine with 500 states\n",
    "input_alphabet = Alphabet.from_strings([\"a\", \"b\", \"c\"])\n",
    "output_alphabet = Alphabet.from_strings(['0', '1'])\n",
    "seed = 100\n",
    "number_of_states = 500\n",
    "automata = generate_moore_machine(input_alphabet, output_alphabet, number_of_states, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converters and Comparators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DFA - Moore machine converter and comparator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.utilities.automata_converter import AutomataConverter\n",
    "from pythautomata.automata_definitions.tomitas_grammars import TomitasGrammars\n",
    "from pythautomata.automata_definitions.sample_moore_machines import SampleMooreMachines\n",
    "from pythautomata.model_comparators.moore_machine_comparison_strategy import MooreMachineComparisonStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tomitas DFA example\n",
    "tomitas = TomitasGrammars.get_automaton_1()\n",
    "\n",
    "# Convert tomitas DFA to moore machine\n",
    "converted_moore_machine = AutomataConverter.convert_dfa_to_moore_machine(tomitas)\n",
    "\n",
    "# Manually created tomitas moore machine\n",
    "tomitas_moore_machine = SampleMooreMachines.get_tomitas_automaton_1()\n",
    "\n",
    "# Comparate tomitas automatons\n",
    "comparison_strategy = MooreMachineComparisonStrategy()\n",
    "comparison_strategy.are_equivalent(automaton1=converted_moore_machine, automaton2=tomitas_moore_machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moore machine - Mealy machine converter and comparator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.utilities.automata_converter import AutomataConverter\n",
    "from pythautomata.automata_definitions.sample_moore_machines import SampleMooreMachines\n",
    "from pythautomata.model_comparators.mealy_machine_comparison_strategy import MealyMachineComparisonStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tomitas DFA example\n",
    "moore_machine = SampleMooreMachines.get_3_states_automaton()\n",
    "\n",
    "# Convert tomitas DFA to moore machine\n",
    "converted_mealy_machine = AutomataConverter.convert_moore_machine_to_mealy_machine(moore_machine)\n",
    "\n",
    "# Manually created mealy machine\n",
    "input_alphabet = Alphabet(frozenset((SymbolStr('a'), SymbolStr('b'))))\n",
    "output_alphabet = Alphabet(frozenset((SymbolStr('a'), SymbolStr('b'), SymbolStr('c'))))\n",
    "\n",
    "a = input_alphabet['a']\n",
    "b = input_alphabet['b']\n",
    "\n",
    "output_a = output_alphabet['a']\n",
    "output_b = output_alphabet['b']\n",
    "output_c = output_alphabet['c']\n",
    "\n",
    "# Defining mealy states\n",
    "stateA = MealyState(name=\"State A\")\n",
    "stateB = MealyState(name=\"State B\")\n",
    "stateC = MealyState(name=\"State C\")\n",
    "\n",
    "# Adding transitions for the previous states\n",
    "stateA.add_transition(a, stateB, output_b)\n",
    "stateA.add_transition(b, stateC, output_c)\n",
    "stateB.add_transition(a, stateC, output_c)\n",
    "stateB.add_transition(b, stateA, output_a)\n",
    "stateC.add_transition(a, stateA, output_a)\n",
    "stateC.add_transition(b, stateB, output_b)\n",
    "\n",
    "# Finaly we create the mealy machine with the alphabets and states previously created \n",
    "mealy_machine = MealyMachine(input_alphabet, output_alphabet, initial_state=stateA, states=set([stateA, stateB, stateC]), \n",
    "                             comparator=MealyComparisonStrategy, \n",
    "                             name=\"mealy machine with 3 states\")\n",
    "\n",
    "# Comparate automatons\n",
    "comparison_strategy = MealyMachineComparisonStrategy()\n",
    "comparison_strategy.are_equivalent(machine1=converted_mealy_machine, machine2=mealy_machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyModelExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymodelextractor in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (0.37.1)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.1 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pymodelextractor) (1.4.1.post1)\n",
      "Requirement already satisfied: pythautomata==0.39.1 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pymodelextractor) (0.39.1)\n",
      "Requirement already satisfied: pydot<2.0.0,>=1.4.2 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pythautomata==0.39.1->pymodelextractor) (1.4.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.7.3 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pythautomata==0.39.1->pymodelextractor) (1.12.0)\n",
      "Requirement already satisfied: numpy in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pythautomata==0.39.1->pymodelextractor) (1.26.4)\n",
      "Requirement already satisfied: graphviz in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pythautomata==0.39.1->pymodelextractor) (0.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.2.1->pymodelextractor) (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.2.1->pymodelextractor) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/martin/miniconda3/envs/neuralchecker/lib/python3.9/site-packages (from pydot<2.0.0,>=1.4.2->pythautomata==0.39.1->pymodelextractor) (3.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymodelextractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Table algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General L*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.model_comparators.moore_machine_comparison_strategy import MooreMachineComparisonStrategy\n",
    "from pythautomata.model_comparators.dfa_comparison_strategy import DFAComparisonStrategy\n",
    "from pymodelextractor.teachers.general_teacher import GeneralTeacher\n",
    "from pythautomata.automata_definitions.sample_moore_machines import SampleMooreMachines\n",
    "from pythautomata.automata_definitions.tomitas_grammars import TomitasGrammars\n",
    "from pymodelextractor.factories.lstar_factory import LStarFactory\n",
    "from pythautomata.utilities.nicaud_dfa_generator import generate_dfa\n",
    "from pythautomata.base_types.alphabet import Alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation using a Moore machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are equal:  True\n"
     ]
    }
   ],
   "source": [
    "# Create the General L* learner that implements the L* algorithm\n",
    "learner = LStarFactory.get_moore_machine_lstar_learner()\n",
    "\n",
    "# Import a sample Moore Machine\n",
    "moore_machine = SampleMooreMachines.get_tomitas_automaton_1()\n",
    "\n",
    "# Create the teacher for the Moore Machine Learner\n",
    "mm_teacher = GeneralTeacher(moore_machine, MooreMachineComparisonStrategy())\n",
    "\n",
    "# Learn the generated Moore Machine\n",
    "teacher = mm_teacher\n",
    "result = learner.learn(teacher) \n",
    "\n",
    "# Show that the learned Moore Machine is equivalent to the generated Moore Machine\n",
    "print(\"Are equal: \", MooreMachineComparisonStrategy().are_equivalent(\n",
    "    result.model, moore_machine))\n",
    "\n",
    "# Export the learned Moore Machine\n",
    "result.model.export('./output_models/mm_lstar/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation using a DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are equal:  True\n"
     ]
    }
   ],
   "source": [
    "# Create the General L* learner that implements the L* algorithm\n",
    "learner = LStarFactory.get_dfa_lstar_learner()\n",
    "\n",
    "# Import a sample DFA\n",
    "dfa =  TomitasGrammars.get_automaton_1()\n",
    "\n",
    "# Create the teacher for the DFA learner\n",
    "dfa_teacher = GeneralTeacher(dfa, DFAComparisonStrategy())\n",
    "\n",
    "# Learn the generated DFA\n",
    "teacher = dfa_teacher\n",
    "result = learner.learn(teacher) \n",
    "\n",
    "# Show that the learned DFA is equivalent to the generated DFA\n",
    "print(\"Are equal: \", DFAComparisonStrategy().are_equivalent(\n",
    "    result.model, dfa))\n",
    "\n",
    "# Export the learned DFA\n",
    "result.model.export('./output_models/dfa_lstar/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partial L*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial L* algorithm enables the inference of a partial automaton. This is particularly useful when there is a need to constrain the time involved in the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are equal:  False\n"
     ]
    }
   ],
   "source": [
    "# Define a maximum time in seconds for the extraction\n",
    "max_extraction_time = 20\n",
    "\n",
    "# Create the General L* learner that implements the L* algorithm with the partial approach\n",
    "learner = LStarFactory.get_partial_dfa_lstar_learner(max_time=max_extraction_time)\n",
    "\n",
    "# Define an input alphabet\n",
    "input_alphabet = Alphabet.from_strings([\"a\", \"b\"])\n",
    "\n",
    "# Generate a random DFA with 1000 states\n",
    "dfa = generate_dfa(input_alphabet, 1000, seed=100)\n",
    "\n",
    "# Create the teacher for the DFA learner\n",
    "dfa_teacher = GeneralTeacher(dfa, DFAComparisonStrategy())\n",
    "\n",
    "# Learn the generated DFA\n",
    "teacher = dfa_teacher\n",
    "result = learner.learn(teacher) \n",
    "\n",
    "# Evaluate if the DFA was learned in the given time\n",
    "print(\"Are equal: \", DFAComparisonStrategy().are_equivalent(\n",
    "    result.model, dfa))\n",
    "\n",
    "# Export the learned DFA\n",
    "result.model.export('./output_models/dfa_partial_lstar/')\n",
    "\n",
    "# Save the Observation Table\n",
    "observation_table = result.info['observation_table']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restart L*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the restart approach to reuse the generated observation table from the last run of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are equal:  True\n"
     ]
    }
   ],
   "source": [
    "# Learn the generated DFA with the saved Observation Table\n",
    "result = learner.learn(teacher, observation_table=observation_table) \n",
    "\n",
    "# Evaluate if the DFA was learned in the given time\n",
    "print(\"Are equal: \", DFAComparisonStrategy().are_equivalent(\n",
    "    result.model, dfa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Tree algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Pack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.learners.observation_tree_learners.observation_pack_learner import ObservationPackLearner\n",
    "from pymodelextractor.teachers.automaton_teacher import DeterministicFiniteAutomatonTeacher\n",
    "from pythautomata.model_comparators.dfa_comparison_strategy import DFAComparisonStrategy\n",
    "from pythautomata.automata_definitions.tomitas_grammars import TomitasGrammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are equal:  True\n"
     ]
    }
   ],
   "source": [
    "# Create the Observation Pack learner that implements the Observation Pack algorithm\n",
    "learner = ObservationPackLearner()\n",
    "\n",
    "# Import a sample DFA\n",
    "dfa = TomitasGrammars.get_automaton_3()\n",
    "\n",
    "# Create the teacher for the DFA learner\n",
    "dfa_teacher = DeterministicFiniteAutomatonTeacher(dfa, DFAComparisonStrategy())\n",
    "\n",
    "# Learn the generated DFA\n",
    "teacher = dfa_teacher\n",
    "result = learner.learn(teacher)\n",
    "\n",
    "# Show that the learned DFA is equivalent to the generated DFA\n",
    "print(\"Are equal: \", DFAComparisonStrategy().are_equivalent(\n",
    "    result.model, dfa))\n",
    "\n",
    "# Export the learned DFA\n",
    "result.model.export('./output_models/dfa_observation_pack/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kearns and Vazirani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.learners.observation_tree_learners.kearns_vazirani_learner import KearnsVaziraniLearner\n",
    "from pymodelextractor.teachers.automaton_teacher import DeterministicFiniteAutomatonTeacher\n",
    "from pythautomata.model_comparators.dfa_comparison_strategy import DFAComparisonStrategy\n",
    "from pythautomata.automata_definitions.tomitas_grammars import TomitasGrammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are equal:  True\n"
     ]
    }
   ],
   "source": [
    "# Create the Observation Pack learner that implements the Kearns and Vazirani algorithm\n",
    "learner = KearnsVaziraniLearner()\n",
    "\n",
    "# Import a sample DFA\n",
    "dfa = TomitasGrammars.get_automaton_4()\n",
    "\n",
    "# Create the teacher for the DFA learner\n",
    "dfa_teacher = DeterministicFiniteAutomatonTeacher(dfa, DFAComparisonStrategy())\n",
    "\n",
    "# Learn the generated DFA\n",
    "teacher = dfa_teacher\n",
    "result = learner.learn(teacher)\n",
    "\n",
    "# Show that the learned DFA is equivalent to the generated DFA\n",
    "print(\"Are equal: \", DFAComparisonStrategy().are_equivalent(\n",
    "    result.model, dfa))\n",
    "\n",
    "# Export the learned DFA\n",
    "result.model.export('./output_models/dfa_kearns_vazirani/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0fe363e8ab1410fba4120e165ad8d88c45f7211f02c52f0870ffe77e2f67f72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
